defaults:
  - model: hifigan_paper
  - metrics: test
  - transforms: empty
  - _self_
dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 1
  num_workers: 4
  pin_memory: True
datasets:
  test:
    _target_: src.datasets.LJSpeechDataset
    name: "test"
    audio_path: "datasets/vocoder_dataset"
    index_audio_path: ${datasets.test.audio_path}
    segment_length: null
    target_sr: 22050
    mel_config:
      _target_: src.utils.MelSpectrogramConfig
      sr: 22050
      win_length: 1024
      hop_length: 256
      n_fft: 1024
      f_min: 0
      f_max: 8000
      n_mels: 80
      power: 1.0
      pad_value: -11.5129251
    calc_mel_for_loss: True
    fmax_loss: null
    n_cache_reuse: 0
inferencer:
  device_tensors: ["audio", "mel", "mel_for_loss", "length"] # which tensors should be on device (ex. GPU)
  device: "auto" # device name or "auto"
  save_path: "resynthesize_results" # any name here, can be a dataset name
  seed: 42
  from_pretrained: "/Users/georgijfatahov/Downloads/lightvoc_176bs_server/model_best.pth" # path to the pretrained model
  warmup_steps: 0
