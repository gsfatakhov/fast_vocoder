defaults:
  - model: hifigan_plus_mel
  - metrics: test
  - transforms: example_only_batch
  - _self_
dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 1
  num_workers: 8
  pin_memory: True
datasets:
  test:
    _target_: src.datasets.LJSpeechDataset
    name: "test"
    audio_path: "datasets/vocoder_dataset"
    index_audio_path: ${datasets.test.audio_path}
    segment_length: null
inferencer:
  device_tensors: ["audio", "mel"] # which tensors should be on device (ex. GPU)
  device: auto # device name or "auto"
  save_path: "resynthesize_results" # any name here, can be a dataset name
  seed: 7
  from_pretrained: "/home/georgii/Documents/vocoder_3/model_best.pth" # path to the pretrained model
